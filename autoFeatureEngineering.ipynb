{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's load the first dataset as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_breast_cancer, load_diabetes, load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data = load_iris()\n",
    "data = load_breast_cancer()\n",
    "# data = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(data['data']), data['target'], random_state=42)\n",
    "X_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets create an automatic feature engineering class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class AutoFeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.numerical_cols = []\n",
    "        self.categorical_cols = []\n",
    "        self.preprocessor = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Separate numerical and categorical columns\n",
    "        self.numerical_cols = X.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "        self.categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "        # Define preprocessing steps for numerical features\n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", MinMaxScaler()),\n",
    "            ('poly', PolynomialFeatures(degree=2))\n",
    "        ])\n",
    "\n",
    "        # Define preprocessing steps for categorical features\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ])\n",
    "\n",
    "        # Combine preprocessing steps for all features\n",
    "        self.preprocessor = ColumnTransformer(transformers=[\n",
    "            (\"num\", numerical_transformer, self.numerical_cols),\n",
    "            (\"cat\", categorical_transformer, self.categorical_cols)\n",
    "        ])\n",
    "\n",
    "        # Fit the preprocessor to the data\n",
    "        self.preprocessor.fit(X)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_transformed = self.preprocessor.transform(X)\n",
    "        return X_transformed\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets create an automatic feature selection class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, metric=accuracy_score):\n",
    "        self.metric = metric\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        # Initialize SelectKBest and SelectFromModel transformers\n",
    "        skb = SelectKBest(chi2, k=int(0.9 * n_features))\n",
    "        sfm = SelectFromModel(RandomForestClassifier(n_estimators=1, random_state=0))\n",
    "        \n",
    "        # Fit both transformers to the data and calculate accuracy scores\n",
    "        skb.fit(X, y)\n",
    "        X_skb = skb.transform(X)\n",
    "        acc_skb = self.metric(y, RandomForestClassifier(n_estimators=1, random_state=0).fit(X_skb, y).predict(X_skb))\n",
    "        \n",
    "        sfm.fit(X, y)\n",
    "        X_sfm = sfm.transform(X)\n",
    "        acc_sfm = self.metric(y, RandomForestClassifier(n_estimators=1, random_state=0).fit(X_sfm, y).predict(X_sfm))\n",
    "        \n",
    "        # Choose the better transformer based on accuracy score\n",
    "        if acc_skb >= acc_sfm:\n",
    "            print(\"Selecting features according to the k highest scores.\")\n",
    "            self.transformer = skb\n",
    "        else:\n",
    "            print(\"selecting features based on importance weights.\")\n",
    "            self.transformer = sfm\n",
    "        \n",
    "        # Fit the chosen transformer to the data\n",
    "        self.transformer.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.transformer.transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we perform auto features engineering on both the train and the test datasets using our AutoFeatureEngineer class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_fe = AutoFeatureEngineer()\n",
    "X_train_transformed = auto_fe.fit_transform(X_train)\n",
    "X_test_transformed = auto_fe.transform(X_test)\n",
    "\n",
    "X_train_transformed_df = pd.DataFrame(X_train_transformed, columns=auto_fe.preprocessor.get_feature_names_out())\n",
    "X_test_transformed_df = pd.DataFrame(X_test_transformed, columns=auto_fe.preprocessor.get_feature_names_out())\n",
    "X_train_transformed_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training a RandomForest Classifier on the baseline data, before performing features engineering or selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=1, random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "pred = forest.predict(X_test)\n",
    "score = sum(pred==y_test)/len(y_test)\n",
    "print(\"The acuuracy of the initial model is:\", score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets train the same classifier on the training set after performing feature engineering trasformation on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.fit(X_train_transformed, y_train)\n",
    "pred_fe = forest.predict(X_test_transformed)\n",
    "score = sum(pred_fe==y_test)/len(y_test)\n",
    "print(\"The accuracy of the model after arithmetic fe is:\", score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets see the performance of the classifier on the baseline data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, pred)\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and here are the results for the tranformed data after feature engineering operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, pred_fe)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix for the initial model:\n",
    "cm_arr = confusion_matrix(y_test, pred)\n",
    "sns.heatmap(cm_arr, cmap='YlGnBu', annot=True, fmt=\"d\").set_title('Confusion Matrix for the initial model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix for the improved model:\n",
    "cm_arr = confusion_matrix(y_test, pred_fe)\n",
    "sns.heatmap(cm_arr, cmap='YlGnBu', annot=True, fmt=\"d\").set_title('Confusion Matrix for the improved model')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets use the FeatureSelector class and perform feature selection operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = FeatureSelector()\n",
    "X_train_selected = selector.fit_transform(X_train_transformed, y_train)\n",
    "X_test_selected = selector.transform(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.fit(X_train_selected, y_train)\n",
    "pred_fe_fs = forest.predict(X_test_selected)\n",
    "score = sum(pred_fe_fs==y_test)/len(y_test)\n",
    "print(\"The accuracy of the model feature selection:\", score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
